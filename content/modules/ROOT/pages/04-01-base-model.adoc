= Deploy and Test the Base Model
include::_attributes.adoc[]

== Deploy the Base Model

Ready to deploy your model? Letâ€™s get started! Follow these steps to bring your model to life in the Data Science Project (`{user}`):

. **Navigate to Your Project**: Head over to your created Data Science Project and locate the **Models** section. 

. **Select the Service Platform**: Click on **Models** and choose the **Single-model service platform** option.
+
[.bordershadow]
image::04/04-01-single-model.png[]

. **Deploy Your Model**: Click on the **Deploy model** button to start the deployment process.
+
[.bordershadow]
image::04/04-01-deploy.png[]

. **Fill Out the Deployment Form**: Youâ€™ll need to provide some essential information. Hereâ€™s what to enter:
   * **Name**: `base`
   * **Serving runtime**: `vLLM ServingRuntime for KServe`
   * **Model server size**: `Small`
   * **Accelerator**: `NVIDIA GPU`
   * **Model route**: Select the option to make your model available through an external route.
   * **Token authentication**: Choose `Require token authentication` and leave the default **Service account name**.
   * **Existing connection**:
   ** **Connection**: `Minio - models`
   ** **Path**: `base_model`
+
[.bordershadow]
image::04/04-01-model-inputs.png[]

. **Deploy and Wait**: After filling out the form, click on **Deploy**. Now, wait while your model gets ready. This might take a moment! â˜•
+
[.bordershadow]
image::04/04-01-model-status.png[]


== Test the Base Model

Congratulations on successfully deploying your model! ðŸŽ‰ Now, it's time to put it to the test. Get ready to send a request to your model and measure its response time. Let's dive in!

=== Environment Setup

Let's set up your environment. Follow these steps to get everything ready:

. **Clone the Repository**: Open your terminal and clone the repository using the following command: ``
+
[source,bash]
----
git clone https://github.com/rhpds/showroom-summit2025-lb2959-neural-magic.git
----
Navigate to the folder containing the lab materials for this section:
+
[source,bash]
----
cd neural-magic-workshop/lab-materials/04
----

. **Update Your Variables**: Open the `request.py` file and update the following variables to match your setup:
+
[source,python]
----
MODEL = "your-model-name"  # Replace with your model name
URL = "your-api-url"       # Replace with your API endpoint
API_KEY = "your-api-key"   # Replace with your API key
----
To fill in these variables, use the information from your deployed model:
   - Set `MODEL` to the name of your model (`base`).
   - Copy the `token` for the `API_KEY`.
   - For the `URL`, check the `internal and external endpoints details` of your deployed model and use the **external endpoint**.
+
[.bordershadow]
image::04/04-01-inference-endpoints.png[]

=== Installation Steps

Before we run the script, ensure you have Git and Python installed. If youâ€™re all set, letâ€™s create a Python virtual environment to keep things tidy:

. **Create and Activate a Virtual Environment**:
+
[source,bash]
----
python -m venv venv
source venv/bin/activate
----

. **Install the Required Dependency**: Now, letâ€™s install the necessary package to interact with your model:
+
[source,bash]
----
pip install langchain_openai
----

=== Running the Script

Youâ€™re almost there! To run the script and measure its execution time, simply execute the following command in your terminal:
[source,bash]
----
time python request.py
----

Once you run the script, youâ€™ll see some exciting output, including:

* The script's output
* Real time (wall clock time)
* User CPU time
* System CPU time

This is your chance to see how well your model performs! ðŸš€


=== Remove model

When you're done testing, donâ€™t forget to clean up. Simply click on the **Delete** button in the **Models** tab to remove the model. 

IMPORTANT: ðŸš¨ Make sure to remove the model before proceeding to the next step to ensure you have enough GPUs available for your next tasks.
[.bordershadow]
image::04/04-01-model-delete.png[]
[.bordershadow]
image::04/04-01-model-delete-base.png[]
